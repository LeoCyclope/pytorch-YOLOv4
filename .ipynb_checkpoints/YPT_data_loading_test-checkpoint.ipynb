{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, '10.1')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('/raid-dgx1/Hasnat/Covoiturage/')\n",
    "from my_utilities_display_related import show_image, show_image_from_file, show_image_subplots\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print((torch.cuda.is_available(), torch.version.cuda)) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Yolo_dataset\n",
    "from tool.tv_reference.utils import collate_fn as val_collate\n",
    "\n",
    "from cfg import Cfg\n",
    "import argparse\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "def get_args(**kwargs):\n",
    "    cfg = kwargs\n",
    "    parser = argparse.ArgumentParser(description='Train the Model on images and target masks',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    # parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=2,\n",
    "    #                     help='Batch size', dest='batchsize')\n",
    "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.001,\n",
    "                        help='Learning rate', dest='learning_rate')\n",
    "    parser.add_argument('-f', '--load', dest='load', type=str, default=None,\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-g', '--gpu', metavar='G', type=str, default='-1',\n",
    "                        help='GPU', dest='gpu')\n",
    "    parser.add_argument('-dir', '--data-dir', type=str, default=None,\n",
    "                        help='dataset dir', dest='dataset_dir')\n",
    "    parser.add_argument('-pretrained', type=str, default=None, help='pretrained yolov4.conv.137')\n",
    "    parser.add_argument('-classes', type=int, default=80, help='dataset classes')\n",
    "    parser.add_argument('-train_label_path', dest='train_label', type=str, default='train.txt', help=\"train label path\")\n",
    "    parser.add_argument(\n",
    "        '-optimizer', type=str, default='adam',\n",
    "        help='training optimizer',\n",
    "        dest='TRAIN_OPTIMIZER')\n",
    "    parser.add_argument(\n",
    "        '-iou-type', type=str, default='iou',\n",
    "        help='iou type (iou, giou, diou, ciou)',\n",
    "        dest='iou_type')\n",
    "    parser.add_argument(\n",
    "        '-keep-checkpoint-max', type=int, default=10,\n",
    "        help='maximum number of checkpoints to keep. If set 0, all checkpoints will be kept',\n",
    "        dest='keep_checkpoint_max')\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    # for k in args.keys():\n",
    "    #     cfg[k] = args.get(k)\n",
    "    cfg.update(args)\n",
    "\n",
    "    return edict(cfg)\n",
    "\n",
    "def collate(batch):\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for img, box in batch:\n",
    "        images.append([img])\n",
    "        bboxes.append([box])\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    images = images.transpose(0, 3, 1, 2)\n",
    "    images = torch.from_numpy(images).div(255.0)\n",
    "    bboxes = np.concatenate(bboxes, axis=0)\n",
    "    bboxes = torch.from_numpy(bboxes)\n",
    "    return images, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_args(**Cfg)\n",
    "\n",
    "config = cfg\n",
    "cfg.batch = 16\n",
    "train_dataset = Yolo_dataset(config.train_label, config, train=True)\n",
    "val_dataset = Yolo_dataset(config.val_label, config, train=False)\n",
    "\n",
    "n_train = len(train_dataset)\n",
    "n_val = len(val_dataset)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch // config.subdivisions, shuffle=True,\n",
    "                          num_workers=16, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003253.jpg\n",
      "007329.jpg\n",
      "000039.jpg\n",
      "006337.jpg\n",
      "004241.jpg\n",
      "009867.jpg\n",
      "002047.jpg\n",
      "008503.jpg\n",
      "002306.jpg\n",
      "009401.jpg\n",
      "[[54, 110, 418, 318, 11]]\n",
      "[[8, 124, 248, 404, 11], [312, 18, 500, 302, 11], [0, 0, 500, 424, 14]]\n",
      "[[128, 80, 368, 324, 3]]\n",
      "[[22, 6, 498, 366, 7]]\n",
      "004368.jpg\n",
      "[[155, 88, 343, 278, 19]]\n",
      "[[306, 90, 498, 366, 19], [0, 26, 308, 374, 19]]\n",
      "009099.jpg\n",
      "[[210, 224, 294, 284, 17]]\n",
      "[[20, 55, 140, 345, 14], [146, 102, 210, 332, 14]]\n",
      "[[2, 4, 218, 374, 5], [433, 280, 499, 374, 6], [350, 221, 460, 297, 6], [255, 244, 365, 360, 6], [254, 211, 330, 269, 6], [319, 183, 365, 221, 6]]\n",
      "got it \n",
      "[[0, 24, 424, 328, 18]]\n",
      "got it \n",
      "got it \n",
      "got it \n",
      "got it \n",
      "[[267, 146, 481, 250, 9], [12, 145, 208, 239, 9], [118, 154, 280, 258, 9]]\n",
      "got it \n",
      "[[145, 127, 285, 333, 2]]\n",
      "got it \n",
      "got it \n",
      "000428.jpg\n",
      "\n",
      "got it \n",
      "\n",
      "007536.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid-dgx1/Hasnat/pytorch-YOLOv4/dataset.py\", line 277, in __getitem__\n    img_path = os.path.join(self.cfg.dataset_dir, img_path)\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/posixpath.py\", line 80, in join\n    a = os.fspath(a)\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b625ca35d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid-dgx1/Hasnat/pytorch-YOLOv4/dataset.py\", line 277, in __getitem__\n    img_path = os.path.join(self.cfg.dataset_dir, img_path)\n  File \"/home/mhasnat/miniconda3/envs/ptenv2/lib/python3.6/posixpath.py\", line 80, in join\n    a = os.fspath(a)\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got it \n",
      "\n",
      "\n",
      "\n",
      "got it \n",
      "\n",
      "\n",
      "\n",
      "got it \n",
      "\n",
      "[[75, 105, 375, 403, 14], [203, 322, 499, 410, 10], [20, 179, 350, 413, 8]]\n",
      "[[244, 120, 500, 312, 17]]\n",
      "\n",
      "005660.jpg\n",
      "\n",
      "\n",
      "got it \n",
      "006189.jpg\n",
      "[[261, 216, 381, 388, 18], [189, 303, 219, 393, 14]]\n",
      "001231.jpg\n",
      "\n",
      "got it \n",
      "006797.jpg\n",
      "006497.jpg\n",
      "005331.jpg\n",
      "[[132, 91, 184, 289, 4], [111, 0, 425, 328, 11]]\n",
      "007166.jpg\n",
      "002893.jpg\n",
      "007311.jpg\n",
      "got it \n",
      "[[222, 126, 306, 212, 8], [52, 142, 180, 262, 8], [294, 176, 498, 374, 17]]\n",
      "006794.jpg\n",
      "000518.jpg\n",
      "005270.jpg\n",
      "\n",
      "[[180, 64, 384, 372, 14], [0, 46, 240, 370, 12]]\n",
      "[[20, 83, 488, 263, 6], [96, 64, 216, 120, 6], [460, 96, 490, 152, 14], [425, 102, 451, 134, 14], [388, 96, 412, 128, 14], [166, 102, 184, 118, 14]]\n",
      "[[70, 141, 290, 447, 12], [100, 83, 244, 303, 14], [84, 86, 160, 138, 6], [0, 90, 40, 138, 6]]\n",
      "got it \n",
      "000454.jpg\n",
      "[[62, 128, 286, 392, 11], [0, 90, 332, 340, 11], [172, 54, 316, 186, 19]]\n",
      "[[0, 6, 492, 374, 13]]\n",
      "[[199, 168, 347, 360, 8], [322, 162, 380, 242, 8], [2, 214, 50, 374, 8]]\n",
      "got it \n",
      "[[92, 116, 372, 202, 0]]\n",
      "[[48, 112, 500, 360, 7]]\n",
      "000203.jpg\n",
      "[[0, 190, 20, 250, 14], [18, 74, 478, 310, 5]]\n",
      "\n",
      "got it \n",
      "got it \n",
      "got it \n",
      "\n",
      "got it \n",
      "[[0, 14, 460, 296, 11]]\n",
      "got it \n",
      "got it \n",
      "\n",
      "got it \n",
      "got it \n",
      "[[50, 165, 166, 331, 8]]\n",
      "got it \n",
      "\n",
      "002873.jpg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "got it \n",
      "\n",
      "\n",
      "\n",
      "got it \n",
      "\n",
      "008951.jpg\n",
      "[[140, 196, 244, 220, 0], [424, 218, 448, 236, 16], [369, 220, 397, 240, 16], [158, 275, 190, 293, 16]]\n",
      "006694.jpg\n",
      "\n",
      "\n",
      "[[2, 16, 374, 500, 11]]\n",
      "got it \n",
      "[[99, 51, 499, 247, 18]]\n",
      "got it \n",
      "got it \n",
      "\n",
      "\n",
      "\n",
      "002208.jpg\n",
      "[[134, 90, 498, 360, 3], [0, 83, 346, 241, 3]]\n",
      "got it \n",
      "\n",
      "005369.jpg\n",
      "[[310, 218, 386, 254, 3]]\n",
      "got it \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in train_loader:\n",
    "    print(i, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "002762.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, targets, _ in data_loader_train:\n",
    "    images = list(img.to(device) for img in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    targets = [modify_target(t_, device) for t_ in targets]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ptenv2)",
   "language": "python",
   "name": "ptenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
