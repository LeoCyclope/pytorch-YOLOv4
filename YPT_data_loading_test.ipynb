{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, '10.1')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('/raid-dgx1/Hasnat/Covoiturage/')\n",
    "from my_utilities_display_related import show_image, show_image_from_file, show_image_subplots\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print((torch.cuda.is_available(), torch.version.cuda)) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Yolo_dataset\n",
    "from tool.tv_reference.utils import collate_fn as val_collate\n",
    "\n",
    "from cfg import Cfg\n",
    "import argparse\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "def get_args(**kwargs):\n",
    "    cfg = kwargs\n",
    "    parser = argparse.ArgumentParser(description='Train the Model on images and target masks',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    # parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=2,\n",
    "    #                     help='Batch size', dest='batchsize')\n",
    "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.001,\n",
    "                        help='Learning rate', dest='learning_rate')\n",
    "    parser.add_argument('-f', '--load', dest='load', type=str, default=None,\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-g', '--gpu', metavar='G', type=str, default='-1',\n",
    "                        help='GPU', dest='gpu')\n",
    "    parser.add_argument('-dir', '--data-dir', type=str, default=None,\n",
    "                        help='dataset dir', dest='dataset_dir')\n",
    "    parser.add_argument('-pretrained', type=str, default=None, help='pretrained yolov4.conv.137')\n",
    "    parser.add_argument('-classes', type=int, default=80, help='dataset classes')\n",
    "    parser.add_argument('-train_label_path', dest='train_label', type=str, default='train.txt', help=\"train label path\")\n",
    "    parser.add_argument(\n",
    "        '-optimizer', type=str, default='adam',\n",
    "        help='training optimizer',\n",
    "        dest='TRAIN_OPTIMIZER')\n",
    "    parser.add_argument(\n",
    "        '-iou-type', type=str, default='iou',\n",
    "        help='iou type (iou, giou, diou, ciou)',\n",
    "        dest='iou_type')\n",
    "    parser.add_argument(\n",
    "        '-keep-checkpoint-max', type=int, default=10,\n",
    "        help='maximum number of checkpoints to keep. If set 0, all checkpoints will be kept',\n",
    "        dest='keep_checkpoint_max')\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    # for k in args.keys():\n",
    "    #     cfg[k] = args.get(k)\n",
    "    cfg.update(args)\n",
    "\n",
    "    return edict(cfg)\n",
    "\n",
    "def collate(batch):\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for img, box in batch:\n",
    "        images.append([img])\n",
    "        bboxes.append([box])\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    images = images.transpose(0, 3, 1, 2)\n",
    "    images = torch.from_numpy(images).div(255.0)\n",
    "    bboxes = np.concatenate(bboxes, axis=0)\n",
    "    bboxes = torch.from_numpy(bboxes)\n",
    "    return images, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_args(**Cfg)\n",
    "\n",
    "config = cfg\n",
    "cfg.batch = 16\n",
    "train_dataset = Yolo_dataset(config.train_label, config, train=True)\n",
    "val_dataset = Yolo_dataset(config.val_label, config, train=False)\n",
    "\n",
    "n_train = len(train_dataset)\n",
    "n_val = len(val_dataset)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch // config.subdivisions, shuffle=True,\n",
    "                          num_workers=16, pin_memory=False, drop_last=True, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_darknet_cfg': True,\n",
       " 'cfgfile': '/raid-dgx1/Hasnat/pytorch-YOLOv4/cfg/yolov4.cfg',\n",
       " 'batch': 16,\n",
       " 'subdivisions': 16,\n",
       " 'width': 608,\n",
       " 'height': 608,\n",
       " 'channels': 3,\n",
       " 'momentum': 0.949,\n",
       " 'decay': 0.0005,\n",
       " 'angle': 0,\n",
       " 'saturation': 1.5,\n",
       " 'exposure': 1.5,\n",
       " 'hue': 0.1,\n",
       " 'learning_rate': 0.001,\n",
       " 'burn_in': 1000,\n",
       " 'max_batches': 500500,\n",
       " 'steps': [400000, 450000],\n",
       " 'policy': [400000, 450000],\n",
       " 'scales': [0.1, 0.1],\n",
       " 'cutmix': 0,\n",
       " 'mosaic': 1,\n",
       " 'letter_box': 0,\n",
       " 'jitter': 0.2,\n",
       " 'classes': 80,\n",
       " 'track': 0,\n",
       " 'w': 608,\n",
       " 'h': 608,\n",
       " 'flip': 1,\n",
       " 'blur': 0,\n",
       " 'gaussian': 0,\n",
       " 'boxes': 60,\n",
       " 'TRAIN_EPOCHS': 300,\n",
       " 'train_label': 'train.txt',\n",
       " 'val_label': '/raid-dgx1/Hasnat/pytorch-YOLOv4/data/val.txt',\n",
       " 'TRAIN_OPTIMIZER': 'adam',\n",
       " 'mixup': 3,\n",
       " 'checkpoints': '/raid-dgx1/Hasnat/pytorch-YOLOv4/checkpoints',\n",
       " 'TRAIN_TENSORBOARD_DIR': '/raid-dgx1/Hasnat/pytorch-YOLOv4/log',\n",
       " 'iou_type': 'iou',\n",
       " 'keep_checkpoint_max': 10,\n",
       " 'load': '/home/mhasnat/.local/share/jupyter/runtime/kernel-8e8c6c9a-ad42-43a8-b262-9810add1c1ea.json',\n",
       " 'gpu': '-1',\n",
       " 'dataset_dir': None,\n",
       " 'pretrained': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in train_loader:\n",
    "    print(i, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, targets, _ in data_loader_train:\n",
    "    images = list(img.to(device) for img in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    targets = [modify_target(t_, device) for t_ in targets]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ptenv2)",
   "language": "python",
   "name": "ptenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
